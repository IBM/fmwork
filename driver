#!/usr/bin/env -S python -u

import argparse
import datetime
import numpy as np
import random
import requests
import time
import traceback

from PIL import Image
from transformers import AutoTokenizer
from vllm import LLM, SamplingParams

class FMworkException(Exception): pass

def banner(*s):
    print(); print(80*'-');
    print(' '.join(list(map(str,s))));
    print(80*'-'); print()

def time_get(): return time.time_ns()
def time_diff(t1, t0): return float(t1 - t0) / 1E9
def time_fmt(t): t = str(t).zfill(9); return '%s.%s' % (t[:-9], t[-9:])

class par: pass # defined in parser
class var: pass # defined below
var.engine  = None
var.__input = None
var.__image = None

def main():

    setup_args()
    setup_input()
    setup_engine()

    ttfts, gens = benchmark()

    show(ttfts, gens)

def setup_args():

    parser = argparse.ArgumentParser()
    parser.add = parser.add_argument
    parser.add('--model_path',           type=str, required=True)
    parser.add('--image_url',            type=str)
    parser.add('--image_width',          type=int)
    parser.add('--image_height',         type=int)
    parser.add('--image_channels',       type=int, default=3)
    parser.add('--input_text',           type=str)
    parser.add('--input_size',           type=int)
    parser.add('--output_size',          type=int, required=True)
    parser.add('--batch_size',           type=int, required=True)
    parser.add('--tensor_parallel_size', type=int, required=True)
    parser.add('--max_num_seqs',         type=int)
    parser.add('--num_scheduler_steps',  type=int, default=1)
    parser.add('--reps',                 type=int, default=5)
    parser.add('--enforce_eager',        action='store_true')
    parser.add('--stop_itl',             type=float)
    parser.add('--stop_ttft',            type=float)

    parser.parse_args(namespace = par)

    if not par.max_num_seqs:
        par.max_num_seqs  = par.batch_size

def setup_engine():

    banner('ENGINE')

    var.engine = LLM(
        model                = par.model_path,
        max_num_seqs         = par.max_num_seqs,
        max_model_len        = par.input_size + par.output_size + 2048,
        tensor_parallel_size = par.tensor_parallel_size,
        enforce_eager        = par.enforce_eager,
        num_scheduler_steps  = par.num_scheduler_steps,
    )

def setup_input():

    if   par.input_text: return setup_input_text()
    elif par.input_size: return setup_input_generate()
    else:
        raise FMworkException(
            'Must define either --input_text or --input_size')

def setup_input_text():

    messages = [
        {
            'role': 'user',
            'content': [
                { 'type': 'image' },
                { 'type': 'text', 'text': par.input_text },
            ],
        },
    ]

    tokenizer = AutoTokenizer.from_pretrained(par.model_path)

    prompt_token_ids = tokenizer.apply_chat_template(
        messages,
        add_generation_prompt = True,
        tokenize = True,
    )

    par.input_size = len(prompt_token_ids)

    inputs = []
    for b in range(par.batch_size):
        inputs.append({
            'prompt_token_ids': prompt_token_ids,
            'multi_modal_data' : { 'image': setup_image() },
        })

    return inputs

def setup_input_generate():

    tokenizer = AutoTokenizer.from_pretrained(par.model_path)
    tokenizer.pad_token = tokenizer.eos_token
    tokenizer.padding_side = "left"

    vocab = list(range(0, tokenizer.vocab_size))
    for i in tokenizer.all_special_ids:
        if i in vocab:
            vocab.remove(i)

    '''
    inputs = []
    for b in range(par.batch_size):
        inputs.append({
            'prompt_token_ids':
                [128000, 128256, 128000] + np.random.choice(vocab, size = par.input_size - 3).tolist(),
            'multi_modal_data' : { 'image': setup_image() },
        })
    '''

    inputs = []
    for b in range(par.batch_size):
        inputs.append({
            'prompt': '<|image|><|begin_of_text|>' + tokenizer.decode(
                np.random.choice(vocab, size = par.input_size).tolist()),
            'multi_modal_data': {
                'image': setup_image()},
        })

    return inputs

def setup_image():

    if par.image_url:                          return setup_image_url()
    elif par.image_width and par.image_height: return setup_image_generate()
    else:
        raise FMworkException(
            'Must define either --image_url '\
            'or --image_width and --image_height.')

def setup_image_url():

    if not var.__image:
        var.__image = Image.open(
            requests.get(par.image_url, stream = True).raw)
        par.image_width, par.image_height = var.__image.size

    return var.__image

def setup_image_generate():

    return Image.fromarray(
        np.random.randint(
            0,
            255,
            (par.image_height, par.image_width, par.image_channels),
            dtype = np.uint8,
        )
    )

def benchmark():

    ttfts = []
    gens  = []

    for r in range(par.reps):
        ttft, gen = run(r)
        ttfts.append(ttft)
        gens.append(gen)

    return ttfts, gens

def run(r):

    banner('RUN %d / %d' % (r + 1, par.reps))

    sampling_params = SamplingParams(
        ignore_eos = True,
        min_tokens = par.output_size,
        max_tokens = par.output_size,
    )

    t0 = time_get()
    outputs = var.engine.generate(
        setup_input(),
        sampling_params,
        use_tqdm = False)
    t1 = time_get()
    dt = time_diff(t1, t0)

    for output in outputs:
        input_size  = len(output.prompt_token_ids)
        output_size = len(output.outputs[0].token_ids)
        batch_size  = par.batch_size

        print()
        print('prompt_token_ids:        ', len(output.prompt_token_ids))
        if output.encoder_prompt_token_ids:
            print('encoder_prompt_token_ids:', len(output.encoder_prompt_token_ids))
        print('outputs[0].token_ids:    ', len(output.outputs[0].token_ids))
        print('output.outputs[0].text:')
        print()
        print(output.outputs[0].text)
        print()
        print('arrival_time        ', output.metrics.arrival_time)
        print('first_scheduled_time', output.metrics.first_scheduled_time)
        print('first_token_time    ', output.metrics.first_token_time)
        print('finished_time       ', output.metrics.finished_time)
        print('time_in_queue       ', output.metrics.time_in_queue)
        print('scheduler_time      ', output.metrics.scheduler_time)

    print(); print(
        'FMWORK OLD',
        input_size,
        output_size,
        batch_size,
        par.tensor_parallel_size,
        '%.3f' % (dt),
        '%.1f' % (1000.0 * dt / output_size),
        '%.1f' % (batch_size * output_size / dt),
    )

    vllm_ttft = output.metrics.first_token_time - output.metrics.first_scheduled_time
    vllm_inf  = output.metrics.finished_time    - output.metrics.arrival_time
    vllm_gen  = output.metrics.finished_time    - output.metrics.first_token_time
    vllm_itl  = vllm_gen * 1000.0 / output_size
    vllm_thp  = batch_size * output_size / vllm_gen

    # note that each concurrent (batched) request
    # will produce an output object in the `outputs` list;
    # while timings should be the same or very close
    # (since the batch is processed as a single request),
    # the output sizes might differ slightly
    # due to encode / decode / encode
    # done to synthesize the prompt;
    # code below will just use the returns
    # from the last output object in the list

    print(); print(
        'FMWORK REP',
        datetime.datetime.now().strftime('%Y%m%d-%H%M%S.%f'),
        r+1, par.reps,
        par.input_size,
        par.output_size,
        par.batch_size,
        par.tensor_parallel_size,
        input_size,
        output_size,
        '%.3f' % (vllm_ttft),
        '%.3f' % (vllm_inf),
        '%.3f' % (vllm_gen),
        '%.3f' % (vllm_itl),
        '%.3f' % (vllm_thp),
    )

    return vllm_ttft, vllm_gen

import numpy as np

def avg(x): return np.mean(x)
def std(x): return np.std(x)
def med(x): return np.median(x)
def mad(x): return med(np.absolute(x - med(x)))

def show(ttfts, gens):

    banner('DONE')

    if par.reps < 2: return

    ign = 0.2
    ign = int(max(ign * len(ttfts), 1))

    _ttfts = ttfts[ign:]
    _gens  = gens[ign:]

    _med = med(_gens)
    _itl = _med * 1000.0 / par.output_size
    _thp = par.batch_size * par.output_size / _med

    print(); print(
        'time', 
        'image_w image_h',
        'ii oo bb tp',
        'mad_ttft mad_gen',
        'ttft gen itl thp')

    print(); print(
        'FMWORK GEN',
        datetime.datetime.now().strftime('%Y%m%d-%H%M%S.%f'),
        par.image_width,
        par.image_height,
        par.input_size,
        par.output_size,
        par.batch_size,
        par.tensor_parallel_size,
        '%.3f' % (mad(_ttfts)), # err ttft
        '%.3f' % (mad(_gens)),  # err gen
        '%.3f' % (med(_ttfts)), # ttft
        '%.3f' % (_med),        # gen
        '%.3f' % (_itl),        # itl
        '%.3f' % (_thp),        # thp
    )

    print()

    '''

    ign = 0.2
    ign = int(max(ign * len(dts), 1))
    rem = dts[ign:]
    med = np.median(rem)
    itl = 1000.0 * med / par.output_size
    thp = par.batch_size * par.output_size / med

    print(
        'FMWORK RES',
        datetime.datetime.now().strftime('%Y%m%d-%H%M%S.%f'),
        par.image_height,
        par.image_width,
        par.input_size,
        par.output_size,
        par.batch_size,
        par.tensor_parallel_size,
        '%.6f' % (med),
        '%.1f' % (itl),
        '%.1f' % (thp),
    )

    print()

    print('Image Height               = %d'   % (par.image_height))
    print('Image Width                = %d'   % (par.image_width))
    print('Input size                = %d'   % (par.input_size))
    print('Output size               = %d'   % (par.output_size))
    print('Batch size                = %d'   % (par.batch_size))
    print('Tensor parallel size      = %d'   % (par.tensor_parallel_size))
    print('Median iteration time (s) = %.6f' % (med))
    print('Inter-token latency (ms)  = %.1f' % (itl))
    print('Throughput (tok/s)        = %.1f' % (thp))

    print()

    '''

if __name__ == '__main__':
    try:
        main()
    except SystemExit as e:
        exit(e.code)
    except FMworkException as e:
        print(e)
        exit(1)
    except KeyboardInterrupt:
        print('Interrupted by user.')
        exit(2)
    except:
        traceback.print_exc()
        exit(3)

