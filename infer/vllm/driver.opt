#!/usr/bin/env -S python -u

import argparse
import fmwork
import torch
import traceback
import vllm

class var: pass
class par: pass

def main():

    params()

    if par.dataset_path:
        fmwork.banner('DATASET')
        t0 = fmwork.time_get()
        fmwork.process_dataset(
            par.dataset_path, par.dataset_format, par.dataset_mode,
            par.model_path)
        t1 = fmwork.time_get()
        print(); print('FMWORK DATASET', '%.6f' % (fmwork.time_diff(t1, t0)))

    llm()
    runs()
    done()

def params():

    fmwork.banner('PARAMS')

    parser = argparse.ArgumentParser()
    parser.add = parser.add_argument

    parser.add('-m', '--model_path', type=str, required=True)
    parser.add(      '--dataset_format', type=str, default='json', choices=['json', 'processed'])
    parser.add(      '--dataset_path', type=str)
    parser.add(      '--dataset_mode', type=str, default='expand', choices=['expand', 'real'])
    parser.add('-i', '--input_size', type=str, required=True)
    parser.add('-o', '--output_size', type=str, required=True)
    parser.add('-b', '--batch_size', type=str, required=True)
    parser.add('-t', '--tensor_parallel', type=int, required=True)
    parser.add('-r', '--reps', type=int, default=3)
    parser.add('-d', '--dtype', type=str, default='auto')
    parser.add('-q', '--quantization', type=str, default=None)
    parser.add('-k', '--kv_cache_dtype', type=str, default='auto')
    parser.add('-u', '--gpu_memory_utilization', type=float, default=0.95)
    parser.add('-e', '--enforce_eager', action='store_true')
    parser.add('-s', '--num_scheduler_steps', type=int, default=1)
    parser.add(      '--use_v2_block_manager', action='store_true')
    parser.add(      '--distributed_executor_backend', default='mp')
    parser.add('-M', '--max_num_seqs', type=int, default=512)
    parser.add('-L', '--max_model_len', type=int)
    parser.add('-B', '--max_num_batched_tokens', type=int)
    parser.add('-c', '--max_seq_len_to_capture', type=int)
    parser.add('-C', '--enable_chunked_prefill',type=str)
    parser.add('--id', type=str)
    parser.add('--show_reps', action='store_true')
    parser.add('--ignore_eos', type=str, default='True')
    parser.add('--debug_outputs', action='store_true')
    parser.add('--trace_outputs', action='store_true')
    parser.add('--stop_itl', type=float)
    parser.add('--stop_ttft', type=float)
    parser.add('--swap_space', type=int, default=4)
    parser.add('--disable_custom_all_reduce', action='store_true')

    parser.parse_args(namespace=par)

    attrs = []
    for attr in dir(par):
        if not attr.startswith('__') and not attr.endswith('__'):
            attrs.append(attr)
    pad = max([len(x) for x in attrs])
    for attr in sorted(attrs):
        print('%-*s = %s' % (
            pad, attr, getattr(par, attr)))

    var.input_sizes  = list(map(int, par.input_size.split(',')))
    var.output_sizes = list(map(int, par.output_size.split(',')))
    var.batch_sizes  = list(map(int, par.batch_size.split(',')))

    if par.quantization == 'None': par.quantization = None

    if not par.enable_chunked_prefill: par.enable_chunked_prefill = False
    else: par.enable_chunked_prefill = \
        par.enable_chunked_prefill == 'True' or \
        par.enable_chunked_prefill == '1'

    par.ignore_eos = par.ignore_eos == 'True' or \
        par.ignore_eos == '1'

    if not par.max_seq_len_to_capture:
        par.max_seq_len_to_capture = max(var.input_sizes) + max(var.output_sizes)

    if not par.max_model_len:
        par.max_model_len = max(var.input_sizes) + max(var.output_sizes)

def llm():

    fmwork.banner('LLM')

    t0 = fmwork.time_get()

    var.llm = vllm.LLM(
        dtype                        = par.dtype,
        enforce_eager                = par.enforce_eager,
        gpu_memory_utilization       = par.gpu_memory_utilization,
        kv_cache_dtype               = par.kv_cache_dtype,
        max_model_len                = par.max_model_len,
        model                        = par.model_path,
        quantization                 = par.quantization,
        tensor_parallel_size         = par.tensor_parallel,
        trust_remote_code            = True,
        num_scheduler_steps          = par.num_scheduler_steps,
        use_v2_block_manager         = par.use_v2_block_manager,
        distributed_executor_backend = par.distributed_executor_backend,
        max_num_seqs                 = par.max_num_seqs,
        max_num_batched_tokens       = par.max_num_batched_tokens,
        enable_chunked_prefill       = par.enable_chunked_prefill,
        swap_space                   = par.swap_space,
        enable_prefix_caching        = False,
        max_seq_len_to_capture       = par.max_seq_len_to_capture,
        disable_custom_all_reduce    = par.disable_custom_all_reduce,
        compilation_config = {
            'cudagraph_capture_sizes': var.batch_sizes,
        },
    )

    t1 = fmwork.time_get()

    print(); print('FMWORK SETUP', '%.6f' % (fmwork.time_diff(t1, t0)))

def runs():

    oo1 = {}
    oor = {}

    for batch_size in var.batch_sizes:
        for input_size in var.input_sizes:
            for output_size in var.output_sizes:
                etim, med, madp = run(input_size, output_size, batch_size)

                if output_size == 1:
                    if input_size not in oo1:
                        oo1[input_size] = {}
                        oor[input_size] = {}
                    oo1[input_size][batch_size] = med
                    oor[input_size][batch_size] = madp
                else:
                    if input_size not in oo1: continue
                    if batch_size not in oo1[input_size]: continue
                    ttft   = oo1[input_size][batch_size]
                    ttft_r = oor[input_size][batch_size]
                    gen    = med - ttft
                    itl    = gen / output_size * 1000.0 # ms
                    thp    = batch_size * output_size / gen

                    print(
                        'FMWORK GEN',
                        etim,
                        input_size,
                        output_size,
                        batch_size,
                        par.tensor_parallel,
                        '%.3f' % (ttft_r),
                        '%.3f' % (madp),
                        '%.3f' % (med),
                        '%.3f' % (gen),
                        '%.3f' % (ttft),
                        '%.1f' % (itl),
                        '%.1f' % (thp),
                    )

                    print()
                    print('TTFT / GEN Metrics')
                    print('------------------')
                    print()
                    print('Experiment timestamp:            %s'   % (etim))
                    print('Model path:                      %s'   % (par.model_path))
                    print('Input size:                      %d'   % (input_size))
                    print('Output size:                     %d'   % (output_size))
                    print('Batch size:                      %d'   % (batch_size))
                    print('Tensor parallel size:            %d'   % (par.tensor_parallel))
                    print('MED  - Median iteration (s):     %.3f (%.3f)' % (med, madp))
                    print('TTFT - Time to first token (s):  %.3f (%.3f)' % (ttft, ttft_r))
                    print('GEN  - Generation time (s):      %.3f' % (gen))
                    print('ITL  - Inter-token latency (ms): %.1f' % (itl))
                    print('THP  - Throughput (tok/s):       %.1f' % (thp))

                    if batch_size > 2:

                        if par.stop_ttft:
                            if ttft > float(par.stop_ttft):
                                print(); print(
                                    'Stopping at TTFT >',
                                    '%.1f' % (par.stop_ttft))
                                return

                        if par.stop_itl:
                            if itl > float(par.stop_itl):
                                print(); print(
                                    'Stopping at ITL >',
                                    '%.1f' % (par.stop_itl))
                                return

def run(input_size, output_size, batch_size):

    fmwork.banner(
        'RUN',
        input_size,  '/',
        output_size, '/',
        batch_size,  '/',
        par.tensor_parallel
    )

    if not par.dataset_path:

        input_batch = fmwork.input_generator(
            par.model_path,
            input_size, batch_size,
            return_tensors='np')

    else:

        input_batch = fmwork.input_dataset(
            par.model_path,
            par.dataset_mode,
            input_size, batch_size)

    sampling_params = vllm.SamplingParams(
        max_tokens = output_size,
        ignore_eos = par.ignore_eos
    )

    kwargs = {
        'prompt_token_ids' : input_batch,
        'sampling_params'  : sampling_params,
        'use_tqdm'         : False,
    }

    fmwork.reset()

    for rep in range(par.reps):
        fmwork.t0()
        outputs = var.llm.generate(**kwargs)
        torch.cuda.synchronize()
        ret = fmwork.t1(
            rep, par.reps,
            input_size, output_size, batch_size,
            par.tensor_parallel,
            par.ignore_eos, outputs,
            par.debug_outputs, par.trace_outputs)

    return ret

def done():

    fmwork.banner('DONE')

if __name__ == '__main__':
    try: main()
    except SystemExit: pass
    except: traceback.print_exc()

