#!/usr/bin/env python3

import os
import sys
sys.path.insert(0, os.path.join(
    os.path.dirname(__file__), '../../utils/python'))
import fmwork

import argparse
import os
import torch
import transformers

#   -------------
#   main function
#   -------------

def main():

    args = setup_args()

    setup_runtime(args)

    model = setup_model(args)

    generator = setup_generator(args)

    bench(args, model, generator)

#   ---------------------------------------
#   read and process command line arguments
#   ---------------------------------------

def setup_args():

    fmwork.banner('ARGS')

    parser = argparse.ArgumentParser()
    parser.add = parser.add_argument
    parser.add('--platform',    type=str, required=True)
    parser.add('--model_class', type=str, required=True)
    parser.add('--model_root',  type=str)
    parser.add('--model_name',  type=str, required=True)
    parser.add('--compile',     action='store_true')
    parser.add('--eval',        action='store_true')
    parser.add('--input_sizes', type=str, required=True)
    parser.add('--batch_sizes', type=str, required=True)
    parser.add('--reps',        type=int, required=True)

    args, opts = parser.parse_known_args()

    args.model_path = (
        os.path.join(args.model_root, args.model_name)
        if args.model_root
        else args.model_name
    )

    args.input_sizes = list(map(int, args.input_sizes.split(',')))
    args.batch_sizes = list(map(int, args.batch_sizes.split(',')))

    fmwork.args.process_opts(args, opts, [
        'compile', 'model', 'torch.call', 'torch.set',
    ], {**globals(), **locals()})

    fmwork.args.show(args)

    return args

#   ----------------------------------------------------------
#   set up platform and engine specific options and components
#   ----------------------------------------------------------

def setup_runtime(args):

    fmwork.banner('RUNTIME')

    print('setup_runtime: torch')

    print('\t', 'torch.call')
    for key in args.subs['torch.call']:
        val = args.subs['torch.call'][key]
        print('\t\t', key, val)
        s = f'torch.{key}({val})'
        eval(s)

    print('\t', 'torch.set')
    for key in args.subs['torch.set']:
        val = args.subs['torch.set'][key]
        print('\t\t', key, val)
        s = f'torch.{key} = {val}'
        exec(s)

    if args.platform == 'spyre': return setup_runtime_spyre(args)

def setup_runtime_spyre(args):

    print('setup_runtime: spyre')

    print('\t', 'torch_sendnn')
    from torch_sendnn import torch_sendnn

#   -----------------------------------------------
#   load model and call other model setup functions
#   -----------------------------------------------

def setup_model(args):

    fmwork.banner('MODEL')

    model = getattr(
        transformers,
        args.model_class,
    ).from_pretrained(
        args.model_path,
        **args.subs['model'],
    )

    if args.platform != 'spyre':
        model = model.to(args.platform)

    if args.compile: model = torch.compile(model, **args.subs['compile'])
    if args.eval:    model.eval()

    print(model)

    return model

#   ----------------------
#   set up input generator
#   ----------------------

def setup_generator(args):

    generator = fmwork.gen.RandomGenerator(args.model_path)

    return generator

#   --------------------------
#   benchmark logic entrypoint
#   --------------------------

def bench(args, model, generator):

    for batch_size in args.batch_sizes:
        for input_size in args.input_sizes:
            bench_combo(args, model, generator, input_size, batch_size)

def bench_combo(args, model, generator, input_size, batch_size):

    fmwork.banner('RUN', input_size, '/', batch_size)

    ts = []; dts = []
    for rep in range(args.reps):
        timings = bench_combo_rep(
            args, model, generator, input_size, batch_size, rep)
        ts.extend(timings[:2])
        dts.append(timings[2])

    show(args, model, input_size, batch_size, ts, dts)

def bench_combo_rep(args, model, generator, input_size, batch_size, rep):

    inputs = generator.prompt(input_size, batch_size, 'pt')

    if args.platform != 'spyre':
        inputs = inputs.to(args.platform)

    t0 = fmwork.time_get()
    model(**inputs)
    if args.platform == 'cuda':
        torch.cuda.synchronize()
    t1 = fmwork.time_get()
    dt = fmwork.time_diff(t1, t0)

    print(
        'FMWORK REP',
        rep + 1, args.reps,
        fmwork.time_format(t0), fmwork.time_format(t1),
        '%.9f' % (dt))

    return t0, t1, dt

#   ------------------------
#   process and show results
#   ------------------------

def show(args, model, input_size, batch_size, ts, dts):

    ign = 0.2
    ign = int(max(ign * len(dts), 1))
    rem = dts[ign:]
    med = fmwork.med(rem)

    print(); print(
        'FMWORK RES',
        fmwork.time_format(ts[0]),
        fmwork.time_format(ts[-1]),
        '%s'   % (args.model_name),
        '%s'   % (args.model_class),
        '%d'   % (input_size),
        '%d'   % (batch_size),
        '%.3f' % (med * 1000.0), # ms/seq
        '%.1f' % (batch_size / med), # seq/s
    )

#   ------------------
#   program entrypoint
#   ------------------

if __name__ == '__main__':
    main(); print()

